{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Privacy Preserving Machine Learning\n",
    "\n",
    "Course taught by Aurélien Bellet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab session: Gaussian mechanism and Differentially Private SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml  # need sklearn >= 0.22\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>Instructions for submitting your report</font>\n",
    "\n",
    "<font color=red>The deadline for sending your report is **Friday, February 23, 2024 at 23h55**.\n",
    "The report is **by teams of 2 students**, should only consist of a **single** `ipynb` file (Jupyter notebook) with your names indicated clearly, and be **submitted via Moodle** (Décision et apprentissage > TP Privacy-Preserving ML > Rendu TP).\n",
    "\n",
    "The grade will be over 20 points, broken down as follows:\n",
    "- Quality of your answers to the questions: **17** points\n",
    "- Quality of the writing and presentation: **2** points\n",
    "- Absence of any bug: **1** point\n",
    "\n",
    "Penalties: **5** points per 12 hours of extra time; **2** points for any failure to respect the other instructions above.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Gaussian mechanism on simple numeric queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part, we will implement the Gaussian mechanism and experiment with simple numeric queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with a dataset from the US Census (also known as the Adult dataset). You can read about the dataset [here](https://archive.ics.uci.edu/ml/datasets/census+income).\n",
    "\n",
    "The following line loads the dataset from [OpenML](https://www.openml.org/) with the `fetch_openml` method of `sklearn`. The option `as_frame=True` (**requires sklearn version >= 0.22**) loads the dataset in `pandas DataFrame` format: this keeps the attributes in their original form and will be more convenient to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_handle = fetch_openml(name='adult', version=2, as_frame=True)\n",
    "dataset = dataset_handle.frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the dataset, in particular the number of rows (individuals), the number of columns (attributes) and what they represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48842 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>198693.0</td>\n",
       "      <td>10th</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227026.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>104626.0</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>3103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>369667.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>104996.0</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age         workclass    fnlwgt     education  education-num  \\\n",
       "0  25.0           Private  226802.0          11th            7.0   \n",
       "1  38.0           Private   89814.0       HS-grad            9.0   \n",
       "2  28.0         Local-gov  336951.0    Assoc-acdm           12.0   \n",
       "3  44.0           Private  160323.0  Some-college           10.0   \n",
       "4  18.0               NaN  103497.0  Some-college           10.0   \n",
       "5  34.0           Private  198693.0          10th            6.0   \n",
       "6  29.0               NaN  227026.0       HS-grad            9.0   \n",
       "7  63.0  Self-emp-not-inc  104626.0   Prof-school           15.0   \n",
       "8  24.0           Private  369667.0  Some-college           10.0   \n",
       "9  55.0           Private  104996.0       7th-8th            4.0   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married  Machine-op-inspct      Own-child  Black    Male   \n",
       "1  Married-civ-spouse    Farming-fishing        Husband  White    Male   \n",
       "2  Married-civ-spouse    Protective-serv        Husband  White    Male   \n",
       "3  Married-civ-spouse  Machine-op-inspct        Husband  Black    Male   \n",
       "4       Never-married                NaN      Own-child  White  Female   \n",
       "5       Never-married      Other-service  Not-in-family  White    Male   \n",
       "6       Never-married                NaN      Unmarried  Black    Male   \n",
       "7  Married-civ-spouse     Prof-specialty        Husband  White    Male   \n",
       "8       Never-married      Other-service      Unmarried  White  Female   \n",
       "9  Married-civ-spouse       Craft-repair        Husband  White    Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  class  \n",
       "0           0.0           0.0            40.0  United-States  <=50K  \n",
       "1           0.0           0.0            50.0  United-States  <=50K  \n",
       "2           0.0           0.0            40.0  United-States   >50K  \n",
       "3        7688.0           0.0            40.0  United-States   >50K  \n",
       "4           0.0           0.0            30.0  United-States  <=50K  \n",
       "5           0.0           0.0            30.0  United-States  <=50K  \n",
       "6           0.0           0.0            40.0  United-States  <=50K  \n",
       "7        3103.0           0.0            32.0  United-States   >50K  \n",
       "8           0.0           0.0            40.0  United-States  <=50K  \n",
       "9           0.0           0.0            10.0  United-States  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  48842.000000  4.884200e+04   48842.000000  48842.000000  48842.000000   \n",
       "mean      38.643585  1.896641e+05      10.078089   1079.067626     87.502314   \n",
       "std       13.710510  1.056040e+05       2.570973   7452.019058    403.004552   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.175505e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.781445e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.376420e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.490400e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    48842.000000  \n",
       "mean        40.422382  \n",
       "std         12.391444  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, d = dataset.shape\n",
    "print(n, d)\n",
    "display(dataset.head(10))\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1 (non-private queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function for each of these types of queries (without privacy) and test them on the dataset:\n",
    "- **Simple count queries**: it takes as input a dataset (`DataFrame`), a categorical attribute (e.g., `\"sex\"`) and a value (e.g., `Male`), and returns how many rows in the dataset have the prescribed attribute value.\n",
    "- **Averaging queries**: it takes as input a dataset and a numeric attribute (e.g., `\"age\"`), and returns the average value of this attribute in the dataset.\n",
    "- **Histogram queries**: it takes as input a dataset and a categorical attribute (e.g., `\"sex\"`), and returns the histogram of counts for this attribute in the dataset (i.e., for each possible value of the attribute, how many rows have this value).\n",
    "\n",
    "Reminder: for a DataFrame `df`, we can access the column corresponding to an attribute `attr` by `df[attr]`. The method `value_counts()` allows to build a histogram of a column.\n",
    "\n",
    "Note: you can use the function `bar_plot_pandas` provided below to draw a bar plot of a pandas Series, which is useful to show histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot_pandas(series1, series2=None, label1=\"Series 1\", label2=\"Series 2\", title=\"\"):\n",
    "    '''\n",
    "    Draws a bar plot of one Pandas Series, or two pandas Series with the same index\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series1 : Series of float\n",
    "        First input\n",
    "    series2 : Series of float, optional\n",
    "        Second input (with same index)\n",
    "    label1 : string, optional\n",
    "        Label for the first series\n",
    "    label2 : string, optional\n",
    "        Label for the second series\n",
    "    title : string, optional\n",
    "        Plot title\n",
    "    '''\n",
    "    if series2 is None:\n",
    "        series1.plot.bar()\n",
    "        plt.legend([label1])\n",
    "    else:\n",
    "        concat_series = pd.DataFrame({label1: series1, label2: series2}).reset_index()\n",
    "        concat_series.plot.bar(x=\"index\", y=[label1, label2], xlabel=\"\", title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_query(df, attribute, value):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataset\n",
    "    attribute : string\n",
    "        Name of an attribute with categorical values\n",
    "    value : string or int\n",
    "        Value of attribute to count\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    count : int\n",
    "        The number of records with `attribute=value` in dataset `df`\n",
    "    '''\n",
    "    \n",
    "    count = (df[attribute] == value).sum() # somme les lignes = True , ce qui donne le count\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_query(df, attribute):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataset\n",
    "    attribute : string\n",
    "        Name of an attribute with numeric values\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    average : float\n",
    "        The average value of `attribute` in dataset `df`\n",
    "    '''\n",
    "        \n",
    "    average = df[attribute].mean() # moyenne\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_query(df, attribute):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataset\n",
    "    attribute : string\n",
    "        Name of an attribute with categorical values\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    histogram : array or Series of int\n",
    "        The histogram of `attribute`, i.e., the number of times each value of `attribute` appears in `df`\n",
    "    '''\n",
    "    \n",
    "    histogram = df[attribute].value_counts() #compte le nombre d'apparition de chaque attribute dans df.\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2 (Gaussian mechanism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the Gaussian mechanism, i.e., a function which takes as input a (non-private) query output, the query's $\\ell_2$ sensitivity, the desired value of $\\epsilon$ and $\\delta$ and a random seed (for reproducibility), and returns a $(\\epsilon,\\delta)$-differentially private estimate of the query. To draw Gaussian noise, check `np.random.normal`. The function should work with queries that output a scalar (like simple count and averaging queries), as well as those that output a vector (like histogram queries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mechanism(q, s2, eps, delta, random_state=None):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    q : float or array/Series of float\n",
    "        The non-private output of the query\n",
    "    s2 : float\n",
    "        The L2 sensitivity of the query\n",
    "    eps : float\n",
    "        Parameter epsilon of differential privacy\n",
    "    delta : float\n",
    "        Parameter delta of differential privacy\n",
    "    random_state : int, optional (default=None)\n",
    "        Random seed\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    private_q : float or array/Series of float\n",
    "        An (eps,delta)-DP evaluation of the query\n",
    "    '''\n",
    "    \n",
    "    rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    if hasattr(q, 'shape'): # query output is multi-dimensional\n",
    "        noise = rng.normal(loc=0, scale=s2 * np.sqrt(2*np.log(1.25/delta))/eps, size=q.shape)\n",
    "        private_q = q + noise\n",
    "    else: # query output is a scalar\n",
    "        noise = rng.normal(loc=0, scale=s2 * np.sqrt(2*np.log(1.25/delta))/eps)\n",
    "        private_q = q + noise\n",
    "        \n",
    "    return private_q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3 (Private computation of count queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to use the Gaussian mechanism to:\n",
    "- privately count the number of males in the dataset\n",
    "- generate a private histogram of the `\"workclass\"` attribute\n",
    "\n",
    "What is the sensitivity of the query in each case?\n",
    "\n",
    "Run the Gaussian mechanism with different values of $\\epsilon$ and $\\delta$, and compute the relative $\\ell_1$-error with respect to the true (non-private) output and discuss the effect of $\\epsilon$ and $\\delta$ on the utility. Recall that the mechanism is random, so unless you fix the seed you will get a different result at each execution. You may also visually compare the private and non-private histograms using the function `bar_plot_pandas` provided at the beginning of the notebook.\n",
    "\n",
    "Note: you may round the outputs of the private mechanism to make them integers if you like. This can be seen as post-processing and thus preserves DP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For the count query, the sensitivity is 1. Changing one record will, in the worst case scenario, replace a male by a female or vice versa. \n",
    ">\n",
    "> For the histogram query of the `\"workclass\"` attribute, the sensitivity is $\\sqrt2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_l1_error(q_true, q_est):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    q_true : float or array/Series of float\n",
    "        True value\n",
    "    q_est : float or array/Series of float\n",
    "        Estimated value\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    l1_error : float\n",
    "        The relative L1 error of `q_est` with respect to and `q_true`: ||q_true-q_est||_1 / ||q_true||_1\n",
    "    '''\n",
    "\n",
    "    if  isinstance(q_true, (int, float)): #add to modify this line,elseit went through every time, event with float\n",
    "        return np.abs(q_true - q_est) / np.abs(q_true)\n",
    "    else:\n",
    "        return np.linalg.norm(q_true - q_est, ord=1) / np.linalg.norm(q_true, ord=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fill with the list of queries in the format (name, query_function, sensitivity)\n",
    "queries = [(dataset.columns[0], average_query, 1),('workclass', histogram_query, np.sqrt(2)),]\n",
    "\n",
    "# fill with the list of values for epsilon and delta\n",
    "eps_list = [0.01, 0.1, 1, 10, 100]\n",
    "delta_list = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "n_runs = 10\n",
    "\n",
    "\n",
    "for name, q, s in queries:\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    error = np.zeros((len(eps_list), len(delta_list), n_runs))\n",
    "    for j, delta in enumerate(delta_list):\n",
    "        for i, eps in enumerate(eps_list):\n",
    "            for r in range(n_runs):\n",
    "                q_true = q(dataset, name)\n",
    "                q_est = gaussian_mechanism(q_true, s, eps, delta, random_state=r+3)\n",
    "                # Compute relative L1 error\n",
    "                error[i, j, r] = relative_l1_error(q_true, q_est)\n",
    "        ax.errorbar(eps_list, error[:, j, :].mean(axis=1), error[:, j, :].std(axis=1),\n",
    "                    label='Gaussian mechanism ($\\delta$=' + \"{:.2e}\".format(delta) + ')')\n",
    "\n",
    "    plt.xlabel(\"$\\epsilon$\")\n",
    "    plt.ylabel(\"$\\ell_1$ error\")\n",
    "    plt.title(\"Query: \" + name)\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the relative $\\ell_1$-error decreases when $\\epsilon$ increases. The influence of $\\delta$ is very small, but here as $\\delta$ increases, the relative $\\ell_1$-error increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "True",
         "type": "bar",
         "x": [
          "Private",
          "Self-emp-not-inc",
          "Local-gov",
          "State-gov",
          "Self-emp-inc",
          "Federal-gov",
          "Without-pay",
          "Never-worked"
         ],
         "y": [
          33906,
          3862,
          3136,
          1981,
          1695,
          1432,
          21,
          10
         ]
        },
        {
         "name": "Private",
         "type": "bar",
         "x": [
          "Private",
          "Self-emp-not-inc",
          "Local-gov",
          "State-gov",
          "Self-emp-inc",
          "Federal-gov",
          "Without-pay",
          "Never-worked"
         ],
         "y": [
          27945.07690636209,
          295.27191454209105,
          4314.217131260119,
          4485.448669991587,
          4027.556329539417,
          6541.786388453936,
          -5834.707612624385,
          6248.498269516043
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Workclass histogram"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare histograms\n",
    "private_workclass = gaussian_mechanism(histogram_query(dataset, 'workclass'), np.sqrt(2), 1e-3, 1e-2)\n",
    "hist=histogram_query(dataset, 'workclass')\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='True', x=hist.index, y=hist),\n",
    "    go.Bar(name='Private', x=hist.index, y=private_workclass)\n",
    "])\n",
    "#add title\n",
    "fig.update_layout(title_text='Workclass histogram')\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using plotly you can choose to hide/show one histogram by clicking on the legend and you can see the exact values of the bars by hovering over them.\n",
    ">\n",
    "> We can easily see the effect of the gaussian noise on the histogram. On the most frequent values, the noise is not very visible, but on the less frequent values, the noise is more visible and can even change the sign of the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Bonus Question</font> (Private computation of  average queries)\n",
    "*(You won't be penalized if you don't answer this question; but can get bonus points if you do)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to use the Gaussian mechanism to privately estimate the average age of people in the dataset.\n",
    "\n",
    "1. Propose and implement simple practical strategies to compute or estimate the sensitivity of this query in the following two scenarios, and discuss the merits and/or drawbacks of your proposals:\n",
    "  - You are the trusted curator: you have access to the raw dataset and would like to release an estimate of the average age of people in the dataset with differential privacy guarantees.\n",
    "  - You are an external data analyst: you do not have access to the raw dataset but only to an API to send queries. You have to convince the trusted curator that the sensitivity you propose is safe.\n",
    "2. Suggest some ideas regarding how we could change a bit the query to get a simple and safe bound on sensitivity, at the expense of possibly introducing some bias in the output. Implement the proposed solution. Hint: the method `clip` from pandas might be useful here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 1: Trusted Curator\n",
    "> As a trusted curator with full access to the dataset, we can directly compute the sensitivity based on the exact range of ages.\n",
    ">\n",
    "> Our strategy is based on **Exact Sensitivity Calculation:** We can calculate the sensitivity as the maximum possible change in the average age when an individual is added or removed from the dataset. \n",
    "> - This strategy has the merit that this precise calculation provides the most accurate sensitivity, ensuring the minimal amount of noise for the desired privacy level. \n",
    "> \n",
    "> - But, as a drawback, this method exposes the curator to the exact range of ages, which might be sensitive if the dataset is small or if extreme ages are rare or sensitive.\n",
    "\n",
    "#### Scenario 2: External Data Analyst\n",
    "> As an external analyst without access to the raw data, proposing a sensitivity requires assumptions or agreements with the curator.\n",
    ">\n",
    "> Our strategy is based on **Agreed-Upon Bounds:** Agree on a plausible range of ages (e.g., 0 to 100 years) to calculate a theoretical maximum sensitivity for the average age query. This bounds the change in average age due to the addition or removal of a single record.\n",
    "> - This strategy has the merit that it does not require access to the raw data, respecting privacy constraints and provides a clear and understandable sensitivity measure that can be easily communicated and agreed upon.\n",
    ">\n",
    "> - But, as a drawback, this method may overestimate the sensitivity if the agreed-upon range is much wider than the actual range of ages in the dataset, leading to unnecessary noise being added. The fixed age range might not apply well to specific populations with a different age distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.64358543876172"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clipped_average_age(df, lower_bound=0, upper_bound=100):\n",
    "    clipped_ages = df['age'].clip(lower_bound, upper_bound)\n",
    "    average_age = clipped_ages.mean()\n",
    "    return average_age \n",
    "\n",
    "clipped_average_age(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Differentially Private Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second part, we will implement and experiment with Differentialy Private Stochastic Gradient Descent (DP-SGD) to privately learn machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You are free to work with any binary classification dataset(s) you like** (you may use more than a single dataset). It is of course possible to work with the US Census dataset used in previous practicals, but you can find other datasets for instance on [OpenML](https://www.openml.org/), [UCI](https://archive.ics.uci.edu/ml/index.php), [sklearn](https://scikit-learn.org/stable/modules/classes.html?highlight=datasets#module-sklearn.datasets).\n",
    "\n",
    "Good candidate datasets should have rather small dimension compared to the number of data points. Examples include US Census in one-hot encoded version (`name='a9a', version=1`), houses (`name='houses', version=2`) and electricity (`name='electricity', version=1`).\n",
    "\n",
    "The code below loads the US Census dataset in one-hot encoded version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48842 123\n"
     ]
    }
   ],
   "source": [
    "X, y = fetch_openml(name='a9a', version=1, return_X_y=True, as_frame=False)\n",
    "n, d = X.shape\n",
    "\n",
    "# convert labels to -1, 1\n",
    "c = np.unique(y)    \n",
    "y[y==c[0]] = -1\n",
    "y[y==c[1]] = 1\n",
    "y = y.astype(float)\n",
    "\n",
    "print(n, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first standardize features, then normalize each point to have unit norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sp.sparse.issparse(X):\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "normalizer = Normalizer()\n",
    "X = normalizer.transform(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the dataset into a train and a test set. Feel free to adapt the size of the training set to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39073, 123) (39073,) (9769, 123) (9769,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.80, random_state=42, stratify=y)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "n_train = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1 (non-private SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first question, we will implement our own simple version of SGD, as well as define our own sklearn-compatible $\\ell_2$-regularized logistic regression estimator. This will be convenient when we will implement a differentially private version in Question 2.\n",
    "\n",
    "Below, you are given several pieces of code:\n",
    "1. A function `sgd` which implements SGD: it is meant to be generic in the sense that it takes as input a function `obj_and_grad` which computes the value and the gradient of the desired objective function. **This function has missing parts that you need to complete**.\n",
    "2. A function `my_logistic_obj_and_grad` (adapted from [the version from sklearn](https://github.com/scikit-learn/scikit-learn/blob/0fb307bf39bbdacd6ed713c00724f8f871d60370/sklearn/linear_model/_logistic.py#L84)) which computes the value and gradient of the logistic regression problem. You do not need to modify this function.\n",
    "3. A class `MySGDLogisticRegression` which defines a sklearn estimator for logistic regression, where the model is fit using SGD using the previous two functions. You do not need to modify this function.\n",
    "\n",
    "Spend a bit of time to get familiar with the code provided, then complete the missing bits in the `sgd` function. Make sure it works by trying it on the binary classification dataset that you previously loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(X, y, gamma, n_iter, obj_and_grad, theta_init, n_batch=1, freq_obj_eval=10,\n",
    "        n_obj_eval=1000, random_state=None):\n",
    "    \"\"\"Stochastic Gradient Descent (SGD) algorithm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape (n, d)\n",
    "        The data\n",
    "    y : array, shape (n,)\n",
    "        Binary labels (-1, 1).\n",
    "    gamma : float | callable\n",
    "        The step size. Can be a constant float or a function\n",
    "        that allows to have a variable step size\n",
    "    n_iter : int\n",
    "        The number of iterations\n",
    "    obj_and_grad : callable\n",
    "        A function which takes as a vector of shape (p,), a dataset of shape (n_batch, d)\n",
    "        and a label vector of shape (n_batch,), and returns the objective value and gradient.\n",
    "    theta_init : array, shape (p,)\n",
    "        The initial value for the model parameters\n",
    "    n_batch : int\n",
    "        Size of the mini-batch to use at each iteration of SGD.\n",
    "    freq_obj_eval : int\n",
    "        Specifies the frequency (in number of iterations) at which we compute the objective\n",
    "    n_obj_eval : int\n",
    "        The number of points on which we evaluate the objective\n",
    "    random_state : int\n",
    "        Random seed to make the algorithm deterministic\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    theta : array, shape=(p,)\n",
    "        The final value of the model parameters\n",
    "    obj_list : list of length (n_iter / freq_obj_eval)\n",
    "        A list containing the value of the objective function computed every freq_obj_eval iterations\n",
    "    \"\"\"\n",
    "    \n",
    "    rng = np.random.RandomState(random_state)\n",
    "    n, d = X.shape\n",
    "    p = theta_init.shape[0]\n",
    "    \n",
    "    theta = theta_init.copy()\n",
    "\n",
    "    # if a constant step size was provided, we turn it into a constant function\n",
    "    if not callable(gamma):\n",
    "        def gamma_func(t):\n",
    "            return gamma\n",
    "    else:\n",
    "        gamma_func = gamma\n",
    "    \n",
    "    # list to record the evolution of the objective (for plotting)\n",
    "    obj_list = []\n",
    "    # we draw a fixed subset of points to monitor the objective\n",
    "    idx_eval = rng.randint(0, n, n_obj_eval)\n",
    "\n",
    "    for t in range(n_iter):\n",
    "        if t % freq_obj_eval == 0:\n",
    "            # evaluate objective\n",
    "            obj, _ = obj_and_grad(theta, X[idx_eval, :], y[idx_eval])\n",
    "            obj_list.append(obj)\n",
    "        \n",
    "        # draw a mini-batch\n",
    "        idx_batch = rng.randint(0, n, n_batch)\n",
    "        X_batch = X[idx_batch, :]\n",
    "        y_batch = y[idx_batch]\n",
    "\n",
    "        # compute the gradient\n",
    "        _, grad = obj_and_grad(theta, X_batch, y_batch)\n",
    "\n",
    "        # update the parameter\n",
    "        theta -= gamma_func(t) * grad\n",
    "\n",
    "    # make sure to compute the objective at the end\n",
    "    obj, _ = obj_and_grad(theta, X[idx_eval, :], y[idx_eval])\n",
    "    obj_list.append(obj)\n",
    "\n",
    "    \n",
    "        \n",
    "    return theta, obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model._base import LinearClassifierMixin, SparseCoefMixin, BaseEstimator\n",
    "from sklearn.utils.extmath import log_logistic, safe_sparse_dot\n",
    "from scipy.special import expit\n",
    "from sklearn.utils.validation import check_X_y\n",
    "\n",
    "def _intercept_dot(w, X, y):\n",
    "    \"\"\"Computes y * np.dot(X, w).\n",
    "\n",
    "    It takes into consideration if the intercept should be fit or not.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w : ndarray, shape (n_features,) or (n_features + 1,)\n",
    "        Coefficient vector.\n",
    "\n",
    "    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "        Training data.\n",
    "\n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Array of labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : ndarray, shape (n_features,)\n",
    "        Coefficient vector without the intercept weight (w[-1]) if the\n",
    "        intercept should be fit. Unchanged otherwise.\n",
    "\n",
    "    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "        Training data. Unchanged.\n",
    "\n",
    "    yz : float\n",
    "        y * np.dot(X, w).\n",
    "    \"\"\"\n",
    "    c = 0.\n",
    "    if w.size == X.shape[1] + 1:\n",
    "        c = w[-1]\n",
    "        w = w[:-1]\n",
    "\n",
    "    z = safe_sparse_dot(X, w) + c\n",
    "    yz = y * z\n",
    "    return w, c, yz\n",
    "\n",
    "\n",
    "def my_logistic_obj_and_grad(theta, X, y, lamb):\n",
    "    \"\"\"Computes the value and gradient of the objective function of logistic regression defined as:\n",
    "    min (1/n) \\sum_i log_loss(theta;X[i,:],y[i]) + (lamb / 2) \\|w\\|^2,\n",
    "    where theta = w (if no intercept), or theta = [w b] (if intercept)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta_init : array, shape (d,) or (d+1,)\n",
    "        The initial value for the model parameters. When an intercept is used, it corresponds to the last entry\n",
    "    X : array, shape (n, d)\n",
    "        The data\n",
    "    y : array, shape (n,)\n",
    "        Binary labels (-1, 1)\n",
    "    lamb : float\n",
    "        The L2 regularization parameter\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    obj : float\n",
    "        The value of the objective function\n",
    "    grad : array, shape (d,) or (d+1,)\n",
    "        The gradient of the objective function\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    grad = np.empty_like(theta)\n",
    "\n",
    "    w, c, yz = _intercept_dot(theta, X, y)\n",
    "\n",
    "    # Logistic loss is the negative of the log of the logistic function\n",
    "    obj = -np.mean(log_logistic(yz)) + .5 * lamb * np.dot(w, w)\n",
    "\n",
    "    z = expit(yz)\n",
    "    z0 = (z - 1) * y\n",
    "\n",
    "    grad[:n_features] = safe_sparse_dot(X.T, z0) / n_samples + lamb * w\n",
    "\n",
    "    # Case where we fit the intercept\n",
    "    if grad.shape[0] > n_features:\n",
    "        grad[-1] = z0.sum() / n_samples\n",
    "    return obj, grad\n",
    "\n",
    "\n",
    "class MySGDLogisticRegression(BaseEstimator, LinearClassifierMixin, SparseCoefMixin):\n",
    "    \"\"\"Our own sklearn estimator for logistic regression defined as:\n",
    "    min (1/n) \\sum_i log_loss(theta;X[i,:],y[i]) + (lamb / 2) \\|w\\|^2,\n",
    "    where theta = [w b]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gamma : float | callable\n",
    "        The step size. Can be a constant float or a function\n",
    "        that allows to have a variable step size\n",
    "    n_iter : int\n",
    "        The number of iterations\n",
    "    lamb : float\n",
    "        The L2 regularization parameter\n",
    "    n_batch : int\n",
    "        Size of the mini-batch to use at each iteration of SGD.\n",
    "    freq_obj_eval : int\n",
    "        Specifies the frequency (in number of iterations) at which we compute the objective\n",
    "    n_obj_eval : int\n",
    "        The number of points on which we evaluate the objectuve\n",
    "    random_state : int\n",
    "        Random seed to make the algorithm deterministic\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    coef_ : (p,)\n",
    "        The weights of the logistic regression model.\n",
    "    intercept_ : (1,)\n",
    "        The intercept term of the logistic regression model.\n",
    "    obj_list_: list of length (n_iter / freq_obj_eval)\n",
    "        A list containing the value of the objective function computed every freq_loss_eval iterations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gamma, n_iter, lamb=0, n_batch=1, freq_obj_eval=10, n_obj_eval=1000, random_state=None):\n",
    "        self.gamma = gamma\n",
    "        self.n_iter = n_iter\n",
    "        self.lamb = lamb\n",
    "        self.n_batch = n_batch\n",
    "        self.freq_obj_eval = freq_obj_eval\n",
    "        self.n_obj_eval = n_obj_eval\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # WARNING: assumes labels are -1, 1\n",
    "        X, y = check_X_y(X, y, accept_sparse='csr', dtype=[np.float64, np.float32], order=\"C\")\n",
    "        self.classes_ = np.unique(y)    \n",
    "        \n",
    "        p = X.shape[1]\n",
    "        theta_init = np.zeros(p+1) # initialize parameters to zero\n",
    "        # define the function for value and gradient needed by SGD\n",
    "        obj_grad = lambda theta, X, y: my_logistic_obj_and_grad(theta, X, y, lamb=self.lamb)\n",
    "        theta, obj_list = sgd(X, y, self.gamma, self.n_iter, obj_grad, theta_init, self.n_batch,\n",
    "                              self.freq_obj_eval, self.n_obj_eval, self.random_state)\n",
    "        \n",
    "        # save the learned model into the appropriate quantities used by sklearn\n",
    "        self.intercept_ = np.expand_dims(theta[-1], axis=0)\n",
    "        self.coef_ = np.expand_dims(theta[:-1], axis=0)\n",
    "        \n",
    "        # also save list of objective values during optimization for plotting\n",
    "        self.obj_list_ = obj_list\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.8402088238304842\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Iteration=%{x}<br>Objective function=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          10,
          20,
          30,
          40,
          50,
          60,
          70,
          80,
          90,
          100,
          110,
          120,
          130,
          140,
          150,
          160,
          170,
          180,
          190,
          200,
          210,
          220,
          230,
          240,
          250,
          260,
          270,
          280,
          290,
          300,
          310,
          320,
          330,
          340,
          350,
          360,
          370,
          380,
          390,
          400,
          410,
          420,
          430,
          440,
          450,
          460,
          470,
          480,
          490,
          500,
          510,
          520,
          530,
          540,
          550,
          560,
          570,
          580,
          590,
          600,
          610,
          620,
          630,
          640,
          650,
          660,
          670,
          680,
          690,
          700,
          710,
          720,
          730,
          740,
          750,
          760,
          770,
          780,
          790,
          800,
          810,
          820,
          830,
          840,
          850,
          860,
          870,
          880,
          890,
          900,
          910,
          920,
          930,
          940,
          950,
          960,
          970,
          980,
          990,
          1000,
          1010,
          1020,
          1030,
          1040,
          1050,
          1060,
          1070,
          1080,
          1090,
          1100,
          1110,
          1120,
          1130,
          1140,
          1150,
          1160,
          1170,
          1180,
          1190,
          1200,
          1210,
          1220,
          1230,
          1240,
          1250,
          1260,
          1270,
          1280,
          1290,
          1300,
          1310,
          1320,
          1330,
          1340,
          1350,
          1360,
          1370,
          1380,
          1390,
          1400,
          1410,
          1420,
          1430,
          1440,
          1450,
          1460,
          1470,
          1480,
          1490,
          1500,
          1510,
          1520,
          1530,
          1540,
          1550,
          1560,
          1570,
          1580,
          1590,
          1600,
          1610,
          1620,
          1630,
          1640,
          1650,
          1660,
          1670,
          1680,
          1690,
          1700,
          1710,
          1720,
          1730,
          1740,
          1750,
          1760,
          1770,
          1780,
          1790,
          1800,
          1810,
          1820,
          1830,
          1840,
          1850,
          1860,
          1870,
          1880,
          1890,
          1900,
          1910,
          1920,
          1930,
          1940,
          1950,
          1960,
          1970,
          1980,
          1990,
          2000,
          2010,
          2020,
          2030,
          2040,
          2050,
          2060,
          2070,
          2080,
          2090,
          2100,
          2110,
          2120,
          2130,
          2140,
          2150,
          2160,
          2170,
          2180,
          2190,
          2200,
          2210,
          2220,
          2230,
          2240,
          2250,
          2260,
          2270,
          2280,
          2290,
          2300,
          2310,
          2320,
          2330,
          2340,
          2350,
          2360,
          2370,
          2380,
          2390,
          2400,
          2410,
          2420,
          2430,
          2440,
          2450,
          2460,
          2470,
          2480,
          2490,
          2500,
          2510,
          2520,
          2530,
          2540,
          2550,
          2560,
          2570,
          2580,
          2590,
          2600,
          2610,
          2620,
          2630,
          2640,
          2650,
          2660,
          2670,
          2680,
          2690,
          2700,
          2710,
          2720,
          2730,
          2740,
          2750,
          2760,
          2770,
          2780,
          2790,
          2800,
          2810,
          2820,
          2830,
          2840,
          2850,
          2860,
          2870,
          2880,
          2890,
          2900,
          2910,
          2920,
          2930,
          2940,
          2950,
          2960,
          2970,
          2980,
          2990,
          3000,
          3010,
          3020,
          3030,
          3040,
          3050,
          3060,
          3070,
          3080,
          3090,
          3100,
          3110,
          3120,
          3130,
          3140,
          3150,
          3160,
          3170,
          3180,
          3190,
          3200,
          3210,
          3220,
          3230,
          3240,
          3250,
          3260,
          3270,
          3280,
          3290,
          3300,
          3310,
          3320,
          3330,
          3340,
          3350,
          3360,
          3370,
          3380,
          3390,
          3400,
          3410,
          3420,
          3430,
          3440,
          3450,
          3460,
          3470,
          3480,
          3490,
          3500,
          3510,
          3520,
          3530,
          3540,
          3550,
          3560,
          3570,
          3580,
          3590,
          3600,
          3610,
          3620,
          3630,
          3640,
          3650,
          3660,
          3670,
          3680,
          3690,
          3700,
          3710,
          3720,
          3730,
          3740,
          3750,
          3760,
          3770,
          3780,
          3790,
          3800,
          3810,
          3820,
          3830,
          3840,
          3850,
          3860,
          3870,
          3880,
          3890,
          3900,
          3910,
          3920,
          3930,
          3940,
          3950,
          3960,
          3970,
          3980,
          3990,
          4000,
          4010,
          4020,
          4030,
          4040,
          4050,
          4060,
          4070,
          4080,
          4090,
          4100,
          4110,
          4120,
          4130,
          4140,
          4150,
          4160,
          4170,
          4180,
          4190,
          4200,
          4210,
          4220,
          4230,
          4240,
          4250,
          4260,
          4270,
          4280,
          4290,
          4300,
          4310,
          4320,
          4330,
          4340,
          4350,
          4360,
          4370,
          4380,
          4390,
          4400,
          4410,
          4420,
          4430,
          4440,
          4450,
          4460,
          4470,
          4480,
          4490,
          4500,
          4510,
          4520,
          4530,
          4540,
          4550,
          4560,
          4570,
          4580,
          4590,
          4600,
          4610,
          4620,
          4630,
          4640,
          4650,
          4660,
          4670,
          4680,
          4690,
          4700,
          4710,
          4720,
          4730,
          4740,
          4750,
          4760,
          4770,
          4780,
          4790,
          4800,
          4810,
          4820,
          4830,
          4840,
          4850,
          4860,
          4870,
          4880,
          4890,
          4900,
          4910,
          4920,
          4930,
          4940,
          4950,
          4960,
          4970,
          4980,
          4990,
          5000,
          5010,
          5020,
          5030,
          5040,
          5050,
          5060,
          5070,
          5080,
          5090,
          5100,
          5110,
          5120,
          5130,
          5140,
          5150,
          5160,
          5170,
          5180,
          5190,
          5200,
          5210,
          5220,
          5230,
          5240,
          5250,
          5260,
          5270,
          5280,
          5290,
          5300,
          5310,
          5320,
          5330,
          5340,
          5350,
          5360,
          5370,
          5380,
          5390,
          5400,
          5410,
          5420,
          5430,
          5440,
          5450,
          5460,
          5470,
          5480,
          5490,
          5500,
          5510,
          5520,
          5530,
          5540,
          5550,
          5560,
          5570,
          5580,
          5590,
          5600,
          5610,
          5620,
          5630,
          5640,
          5650,
          5660,
          5670,
          5680,
          5690,
          5700,
          5710,
          5720,
          5730,
          5740,
          5750,
          5760,
          5770,
          5780,
          5790,
          5800,
          5810,
          5820,
          5830,
          5840,
          5850,
          5860,
          5870,
          5880,
          5890,
          5900,
          5910,
          5920,
          5930,
          5940,
          5950,
          5960,
          5970,
          5980,
          5990,
          6000,
          6010,
          6020,
          6030,
          6040,
          6050,
          6060,
          6070,
          6080,
          6090,
          6100,
          6110,
          6120,
          6130,
          6140,
          6150,
          6160,
          6170,
          6180,
          6190,
          6200,
          6210,
          6220,
          6230,
          6240,
          6250,
          6260,
          6270,
          6280,
          6290,
          6300,
          6310,
          6320,
          6330,
          6340,
          6350,
          6360,
          6370,
          6380,
          6390,
          6400,
          6410,
          6420,
          6430,
          6440,
          6450,
          6460,
          6470,
          6480,
          6490,
          6500,
          6510,
          6520,
          6530,
          6540,
          6550,
          6560,
          6570,
          6580,
          6590,
          6600,
          6610,
          6620,
          6630,
          6640,
          6650,
          6660,
          6670,
          6680,
          6690,
          6700,
          6710,
          6720,
          6730,
          6740,
          6750,
          6760,
          6770,
          6780,
          6790,
          6800,
          6810,
          6820,
          6830,
          6840,
          6850,
          6860,
          6870,
          6880,
          6890,
          6900,
          6910,
          6920,
          6930,
          6940,
          6950,
          6960,
          6970,
          6980,
          6990,
          7000,
          7010,
          7020,
          7030,
          7040,
          7050,
          7060,
          7070,
          7080,
          7090,
          7100,
          7110,
          7120,
          7130,
          7140,
          7150,
          7160,
          7170,
          7180,
          7190,
          7200,
          7210,
          7220,
          7230,
          7240,
          7250,
          7260,
          7270,
          7280,
          7290,
          7300,
          7310,
          7320,
          7330,
          7340,
          7350,
          7360,
          7370,
          7380,
          7390,
          7400,
          7410,
          7420,
          7430,
          7440,
          7450,
          7460,
          7470,
          7480,
          7490,
          7500,
          7510,
          7520,
          7530,
          7540,
          7550,
          7560,
          7570,
          7580,
          7590,
          7600,
          7610,
          7620,
          7630,
          7640,
          7650,
          7660,
          7670,
          7680,
          7690,
          7700,
          7710,
          7720,
          7730,
          7740,
          7750,
          7760,
          7770,
          7780,
          7790,
          7800,
          7810,
          7820,
          7830,
          7840,
          7850,
          7860,
          7870,
          7880,
          7890,
          7900,
          7910,
          7920,
          7930,
          7940,
          7950,
          7960,
          7970,
          7980,
          7990,
          8000,
          8010,
          8020,
          8030,
          8040,
          8050,
          8060,
          8070,
          8080,
          8090,
          8100,
          8110,
          8120,
          8130,
          8140,
          8150,
          8160,
          8170,
          8180,
          8190,
          8200,
          8210,
          8220,
          8230,
          8240,
          8250,
          8260,
          8270,
          8280,
          8290,
          8300,
          8310,
          8320,
          8330,
          8340,
          8350,
          8360,
          8370,
          8380,
          8390,
          8400,
          8410,
          8420,
          8430,
          8440,
          8450,
          8460,
          8470,
          8480,
          8490,
          8500,
          8510,
          8520,
          8530,
          8540,
          8550,
          8560,
          8570,
          8580,
          8590,
          8600,
          8610,
          8620,
          8630,
          8640,
          8650,
          8660,
          8670,
          8680,
          8690,
          8700,
          8710,
          8720,
          8730,
          8740,
          8750,
          8760,
          8770,
          8780,
          8790,
          8800,
          8810,
          8820,
          8830,
          8840,
          8850,
          8860,
          8870,
          8880,
          8890,
          8900,
          8910,
          8920,
          8930,
          8940,
          8950,
          8960,
          8970,
          8980,
          8990,
          9000,
          9010,
          9020,
          9030,
          9040,
          9050,
          9060,
          9070,
          9080,
          9090,
          9100,
          9110,
          9120,
          9130,
          9140,
          9150,
          9160,
          9170,
          9180,
          9190,
          9200,
          9210,
          9220,
          9230,
          9240,
          9250,
          9260,
          9270,
          9280,
          9290,
          9300,
          9310,
          9320,
          9330,
          9340,
          9350,
          9360,
          9370,
          9380,
          9390,
          9400,
          9410,
          9420,
          9430,
          9440,
          9450,
          9460,
          9470,
          9480,
          9490,
          9500,
          9510,
          9520,
          9530,
          9540,
          9550,
          9560,
          9570,
          9580,
          9590,
          9600,
          9610,
          9620,
          9630,
          9640,
          9650,
          9660,
          9670,
          9680,
          9690,
          9700,
          9710,
          9720,
          9730,
          9740,
          9750,
          9760,
          9770,
          9780,
          9790,
          9800,
          9810,
          9820,
          9830,
          9840,
          9850,
          9860,
          9870,
          9880,
          9890,
          9900,
          9910,
          9920,
          9930,
          9940,
          9950,
          9960,
          9970,
          9980,
          9990,
          10000
         ],
         "xaxis": "x",
         "y": [
          0.6931471805599454,
          0.6144022518729192,
          0.5892698416555512,
          0.6026993037099203,
          0.5698082213402138,
          0.5654901218227094,
          0.5747552404102222,
          0.5574788660329419,
          0.55394058474269,
          0.5591660410291222,
          0.5471905399693817,
          0.5393687619417235,
          0.5376543441999362,
          0.5314647835601733,
          0.526563657107861,
          0.5258842459545754,
          0.5247272161654298,
          0.5256398643213169,
          0.5216324147893461,
          0.5167685451205064,
          0.5170804400050009,
          0.5152772798829081,
          0.5174272471270266,
          0.5182872558960508,
          0.5177776949872991,
          0.5141912886612181,
          0.5106942959039977,
          0.5095292488727958,
          0.5131415235986958,
          0.5105466750646805,
          0.5126375205417717,
          0.512029336499291,
          0.5201065470440842,
          0.5296345464371853,
          0.5256503696382311,
          0.5184155960831877,
          0.5226232552385093,
          0.5145320525501599,
          0.5089142835264034,
          0.51899964304918,
          0.5108969787517775,
          0.5055893600558874,
          0.5019776077764244,
          0.5015824068454021,
          0.5016084355694745,
          0.4982241398020268,
          0.4956047351486255,
          0.4918136086007731,
          0.4910515259862906,
          0.48910599050998504,
          0.4884880162150489,
          0.4874109695472138,
          0.48759327593822444,
          0.48605221323040054,
          0.48550479463958607,
          0.4849145606973717,
          0.4847619782894527,
          0.4921256178809567,
          0.4879988677754284,
          0.4859938288063537,
          0.48195200943430727,
          0.4841126745255336,
          0.48473586543825464,
          0.48239976348015473,
          0.4820357834934439,
          0.4786991225334315,
          0.4781262600855533,
          0.47699236117063665,
          0.4779675968616291,
          0.4766120206134823,
          0.4757015717307987,
          0.4786327531970342,
          0.490986074536723,
          0.49415131896610376,
          0.4882689291089932,
          0.4827238935260004,
          0.47393809758316036,
          0.47132696257133594,
          0.47005221634289696,
          0.46890169037565194,
          0.4689377439576176,
          0.46874195492150056,
          0.46843687896045433,
          0.4693297559963229,
          0.4675634950996698,
          0.46863705217078816,
          0.46739082377235414,
          0.4693527054141726,
          0.4660959922968142,
          0.464501308300613,
          0.4637408776245925,
          0.4631072419791055,
          0.46250696327099516,
          0.46172702394017345,
          0.4614011402202805,
          0.46053920409356897,
          0.4602686810829633,
          0.4605645486187904,
          0.4594565215422772,
          0.46002103541421296,
          0.46099411300379245,
          0.4619447237477757,
          0.46314555560228954,
          0.45961364281592,
          0.4587633161252368,
          0.45558928497804085,
          0.4554106571729425,
          0.45653675185954357,
          0.4551827998612055,
          0.4548723701911489,
          0.4530421154798031,
          0.4557968599493405,
          0.4558276160129892,
          0.4520571361676801,
          0.4537358813044419,
          0.4519276230115971,
          0.4503511798707244,
          0.4531912937405641,
          0.44984252315765183,
          0.44997772778168754,
          0.44845005545949995,
          0.44705069037849077,
          0.4513101672163852,
          0.44901883496487005,
          0.4516259608006935,
          0.456398151881386,
          0.45640615200849566,
          0.46286093985745475,
          0.4581292770257449,
          0.447594272917632,
          0.45165597816611264,
          0.44851491552766526,
          0.4451603751454977,
          0.45252195406513807,
          0.44911467413463435,
          0.4410164364771001,
          0.43883760587528436,
          0.4383267639070809,
          0.43807307540040163,
          0.4372758237552344,
          0.4363928233152933,
          0.4357574858036601,
          0.4364364004456552,
          0.4385710076971445,
          0.4398425260667905,
          0.4368633209106018,
          0.43381227618894536,
          0.43370714985417896,
          0.43629905395876134,
          0.4356115421620118,
          0.43190536160126475,
          0.431337449720173,
          0.43128099523385993,
          0.4306486081213004,
          0.4297083026015549,
          0.42974466885514734,
          0.4299640036249327,
          0.42934626094614986,
          0.4293322340396973,
          0.4280062759339758,
          0.4277684935570989,
          0.4281198582481608,
          0.43002920503886144,
          0.42874041197892826,
          0.42971455397830455,
          0.42742590645679757,
          0.426398663924551,
          0.42647179336482904,
          0.4246253718374634,
          0.42450042821140327,
          0.42473453502804964,
          0.42697059296790624,
          0.4270121297546601,
          0.42695195421907595,
          0.4264090166061783,
          0.4237289662255298,
          0.42167559836666524,
          0.421117157165983,
          0.42046213352069306,
          0.42032399502631723,
          0.42058316056735473,
          0.42268607301216377,
          0.4211123230924584,
          0.4190166326832202,
          0.4182183395289676,
          0.41806623525809666,
          0.41759693732078834,
          0.41691314579856614,
          0.4172350763348166,
          0.4168658650777272,
          0.4162197942431353,
          0.41630698076067424,
          0.41668375147064657,
          0.41887772141518315,
          0.4208167265653846,
          0.4226220369921524,
          0.4176653079487877,
          0.4194780561594015,
          0.41916243847845597,
          0.41633635722176,
          0.41646106386597503,
          0.4157557879930657,
          0.4198677998127331,
          0.4233477567434221,
          0.4244670637721994,
          0.42798980291779104,
          0.4207948251532857,
          0.42094154586187577,
          0.41869223039252285,
          0.4182708578680645,
          0.41833134964799135,
          0.4195331551671305,
          0.41902449649848483,
          0.4148326853153266,
          0.4123518217772055,
          0.41166216964291075,
          0.40997455203015676,
          0.4095074199029958,
          0.40923575204919477,
          0.4109709552783561,
          0.4096221617572081,
          0.4081487066630291,
          0.4073954294416253,
          0.4074365239035844,
          0.4074844340156954,
          0.40627306965330734,
          0.40588727138971376,
          0.40689322622108365,
          0.40921012081672786,
          0.4072495069187157,
          0.4045675123667328,
          0.4056674326795992,
          0.40536441543592855,
          0.4050845826599985,
          0.4066459238384296,
          0.4050058743142344,
          0.4044240462246507,
          0.4036320123162041,
          0.4035106283957778,
          0.40404009586567385,
          0.4027477364149469,
          0.40495412255314883,
          0.40534019288587114,
          0.40288144510754115,
          0.4026473367878381,
          0.40251457397639234,
          0.4049121438217881,
          0.4038796950365065,
          0.40260390398892926,
          0.4032877787019854,
          0.4023117316274797,
          0.40138908708209625,
          0.4020007463999231,
          0.40281563172165563,
          0.4013401501003118,
          0.4020895444076926,
          0.4004458949349971,
          0.3998022526692582,
          0.39982737954698655,
          0.3996647277683845,
          0.399719944583831,
          0.40045303388234926,
          0.4031261676540749,
          0.4001169944425627,
          0.3999757855953337,
          0.4000122622526108,
          0.3994187711457098,
          0.39774997452940525,
          0.39962134859963544,
          0.40052231050977793,
          0.3968568954749418,
          0.3965457354233879,
          0.396312561513905,
          0.3959976285109153,
          0.39572964606873473,
          0.39549857660174054,
          0.3962385005743254,
          0.39744224651505394,
          0.3956021846741434,
          0.3952688682156651,
          0.3954294985616999,
          0.3961065674894229,
          0.3974135066907089,
          0.3953441433458238,
          0.3956233456169905,
          0.3946921826053783,
          0.39494476443650556,
          0.39330958508029423,
          0.3941156295544809,
          0.39583873965086125,
          0.40393255389519606,
          0.3993290736280333,
          0.4042870755724368,
          0.4033819001834164,
          0.39872245089027775,
          0.3998891946349747,
          0.39664095278950356,
          0.39686429665668904,
          0.3989768201260194,
          0.40169414004975657,
          0.39762927148071836,
          0.40131459617740345,
          0.3990246934748219,
          0.3942414306759214,
          0.3913926815332626,
          0.3921210725897945,
          0.38947242936882887,
          0.3897596659801477,
          0.38921033165203084,
          0.3916890191313963,
          0.38959419271048945,
          0.3887550777665412,
          0.3882634039545222,
          0.3891462006730139,
          0.388273897460585,
          0.38767604569739883,
          0.387575535745705,
          0.38761259239079837,
          0.38730770988278324,
          0.38840049476818833,
          0.38709562429188643,
          0.387932565080892,
          0.38986761233729594,
          0.38883524083120224,
          0.38727734617924287,
          0.3861655622183705,
          0.3858933799854335,
          0.38555004772539087,
          0.3924176629143293,
          0.3948341161192211,
          0.3911942583962492,
          0.3923735767716233,
          0.3888713392003398,
          0.3880654940305601,
          0.3860106119943968,
          0.38475626195247986,
          0.38822667581665365,
          0.38516399057124545,
          0.38439947092593946,
          0.3843873066643622,
          0.3839795810186439,
          0.3837189199938966,
          0.3838720558075509,
          0.3842466006961256,
          0.38469246816661073,
          0.38322592827192864,
          0.38284148553185615,
          0.38312017370831086,
          0.38382469034647704,
          0.38264440475766925,
          0.38242141143286895,
          0.383333213036455,
          0.383168596884438,
          0.3819324876861707,
          0.38202405075798107,
          0.3818835726917467,
          0.38415184390412005,
          0.38192436578989974,
          0.3823359209302858,
          0.3811015248923437,
          0.38146103182413926,
          0.382064475757257,
          0.38353027483662266,
          0.38217595351165357,
          0.3817465957019249,
          0.3815390402986434,
          0.3907935640273302,
          0.3868080566838947,
          0.38237851503516396,
          0.38039378393162404,
          0.3791991030221793,
          0.3808456629497061,
          0.3787219294015038,
          0.3784612500966531,
          0.37809619856246207,
          0.3778640363995121,
          0.377859866436614,
          0.3778295815943948,
          0.37705896057038335,
          0.37690755433939443,
          0.3766088572279873,
          0.37644090115821455,
          0.3818274209036543,
          0.38306417264653886,
          0.38185887099972776,
          0.3781741825912519,
          0.3808130221250949,
          0.38561570782439825,
          0.3926996288130633,
          0.3842910244074151,
          0.3844153543651635,
          0.3794579729686087,
          0.38015914036174014,
          0.3831693988619351,
          0.37922401139027134,
          0.38393422112568676,
          0.3787329712550523,
          0.37621272037667247,
          0.37497370176412287,
          0.37450799097330595,
          0.3739714190157698,
          0.3736594613296342,
          0.37412702817280746,
          0.37483140846651003,
          0.3739763498041565,
          0.37328729934368177,
          0.37316157745717204,
          0.37311068388423935,
          0.3727026816276347,
          0.37256538120586774,
          0.37249333801873136,
          0.3736668457019519,
          0.372331369074637,
          0.3722357333834887,
          0.37186661275407434,
          0.3717367654342954,
          0.3719610741921987,
          0.3735620528000652,
          0.371405887843901,
          0.3725733361503566,
          0.37178094630167846,
          0.371302176300362,
          0.3703624339684396,
          0.370272433256567,
          0.37048141998956496,
          0.370038773463904,
          0.3694852742260922,
          0.37120829182311266,
          0.3698424343919465,
          0.3701620898022408,
          0.369254174347696,
          0.369065000228605,
          0.36971583003739694,
          0.3686536697658579,
          0.36877942187218443,
          0.36842790606021203,
          0.36959469951432883,
          0.3694580153256727,
          0.36833133556677267,
          0.36883252007515405,
          0.3680769010386498,
          0.36871612847624846,
          0.36830342875741984,
          0.36794901205089886,
          0.3679198239803165,
          0.36781934378669917,
          0.36745543236216305,
          0.3673722707997129,
          0.3676662222175349,
          0.3675768376004257,
          0.3686010368818333,
          0.371904003649177,
          0.3872968800458944,
          0.38858807346530366,
          0.39563298263384994,
          0.3851526723307032,
          0.38029832093520805,
          0.3726911677909187,
          0.38026989706492,
          0.3746294085331717,
          0.3719688857715477,
          0.36909684046979896,
          0.373267045267969,
          0.37648702897395847,
          0.37231366730510335,
          0.36727123385157234,
          0.3676535115101536,
          0.3712736330732107,
          0.37117987401629,
          0.3686848276613324,
          0.3691685938428333,
          0.36802459009903726,
          0.3662296985124395,
          0.3656121814446593,
          0.36590887350518475,
          0.3660271876746383,
          0.36553828969095875,
          0.3647257990484882,
          0.3654927201513116,
          0.36461212518595554,
          0.3659473099754062,
          0.3663581396778495,
          0.36723853837417647,
          0.36545730690870254,
          0.36404539941926967,
          0.3637440087722698,
          0.36388741718877626,
          0.3632581138636343,
          0.3630612581146347,
          0.36327130002200136,
          0.36340031413061824,
          0.3628004044135856,
          0.36269497148819524,
          0.36267730367606976,
          0.3634733373473769,
          0.3624854894874491,
          0.3630940373320226,
          0.36220391032060595,
          0.36319785577883257,
          0.3617412211786416,
          0.361589278105395,
          0.36160026649747595,
          0.3618726829784332,
          0.3616053593504603,
          0.3614373131860278,
          0.3621236816643109,
          0.366276891028113,
          0.3658198013357619,
          0.37029979601039725,
          0.3703355077327298,
          0.3658006052961824,
          0.36643838558267566,
          0.3644573651587882,
          0.36290299745099425,
          0.3604718760450371,
          0.3604321069748737,
          0.3604753907299769,
          0.36064988776913465,
          0.36006939150036105,
          0.36002097681777995,
          0.3602473749052318,
          0.360223188875362,
          0.3601128438097928,
          0.3601945062013103,
          0.35989128576796214,
          0.3601381026261499,
          0.36183655419777266,
          0.3657464460085579,
          0.3668942748406552,
          0.3708307618570691,
          0.38145807803317183,
          0.37495676120037447,
          0.3699062168453895,
          0.3656559798161317,
          0.361100542285929,
          0.35890766029951826,
          0.3589896963513141,
          0.3588159262321144,
          0.3587007928231556,
          0.3590153073751898,
          0.3584579804931972,
          0.3590828557870431,
          0.36073897079882,
          0.35821794373892873,
          0.3587140485802536,
          0.35830081796513275,
          0.35833681570516296,
          0.35949496085845584,
          0.35796356028629694,
          0.3583931097333762,
          0.35834240682616286,
          0.35924341846141966,
          0.35851824978024416,
          0.36527205142930974,
          0.3636278401102489,
          0.36430583678520895,
          0.36344383216104614,
          0.362668863558884,
          0.35887000957403564,
          0.35769198299493854,
          0.35760636383429256,
          0.35719363070212434,
          0.3574948073287784,
          0.35706471051373867,
          0.35687823267517776,
          0.35728695068417354,
          0.3566888155332499,
          0.35643886807038044,
          0.3562482998337324,
          0.35676925063209386,
          0.3564370977191174,
          0.35639355360211467,
          0.3576208628914406,
          0.35651745196636614,
          0.3567302860445925,
          0.35607232606875555,
          0.3559039322889068,
          0.3561271314652912,
          0.35601376351922115,
          0.35675938705809124,
          0.3562839774186123,
          0.35735531004134485,
          0.3557448922476615,
          0.3557369900073229,
          0.3553476966265717,
          0.3552257608902986,
          0.35512115941147854,
          0.3557800392583354,
          0.35660669846841564,
          0.35522718775796047,
          0.35704874820415966,
          0.35626426547878554,
          0.3579520990875426,
          0.3586240171428042,
          0.3585150340269539,
          0.3560750042044842,
          0.35584759265617544,
          0.3615622485343365,
          0.36029639491737153,
          0.35857331729833025,
          0.357377368753985,
          0.35555646609267105,
          0.35591597190788227,
          0.3563872844340208,
          0.35618570859391174,
          0.354383447817933,
          0.3565666147203908,
          0.3595770841591715,
          0.35844831094458673,
          0.35571631752843597,
          0.3533118018231571,
          0.3529499293385046,
          0.352938788484807,
          0.35268429487510683,
          0.3529671198196616,
          0.3527260184154767,
          0.352703892841423,
          0.35289069286076746,
          0.35273248772463744,
          0.35255317968154737,
          0.35239536106724584,
          0.3525090920831972,
          0.35254574732247806,
          0.3537656209307744,
          0.3527774523210006,
          0.35227746810645033,
          0.3526339221341729,
          0.3525254535339393,
          0.3532754297581167,
          0.35450020517964037,
          0.3519234135216784,
          0.3516783048457815,
          0.3522698711899553,
          0.3548556145184048,
          0.35245624084124433,
          0.35120574688175027,
          0.35103668695718887,
          0.3515257958383531,
          0.3528697714123031,
          0.36256065732190523,
          0.3581850208155056,
          0.35623425788966656,
          0.35515552898851427,
          0.35189657048674294,
          0.3513428949839767,
          0.35100955086449287,
          0.3529838645865134,
          0.3534076497307678,
          0.35371732172929093,
          0.35466532040486626,
          0.35726343114484155,
          0.354603139790407,
          0.3573855651065788,
          0.35641580368099585,
          0.3574007515792367,
          0.35670235872188427,
          0.35186513468933867,
          0.34998307738821155,
          0.34988496915276734,
          0.349833991465254,
          0.3496613255438691,
          0.3497265424118598,
          0.34973613101310647,
          0.3503341144035915,
          0.34978689679223646,
          0.34961569902363615,
          0.34936878610909156,
          0.3493820456330441,
          0.35102564253430946,
          0.3525283608826097,
          0.35551302009668334,
          0.35756805732074476,
          0.3583563476819325,
          0.35880854392462036,
          0.3551351601965566,
          0.35444168076700805,
          0.3521617190717603,
          0.34923978535345074,
          0.34878659405270723,
          0.34948823966773096,
          0.34869503798999674,
          0.3491375172099557,
          0.3497790069101484,
          0.349465898777706,
          0.3514226265781888,
          0.34825331925430797,
          0.3480398848307499,
          0.3488918037451823,
          0.34800435655194134,
          0.34776888029074704,
          0.3477955816721944,
          0.35002942589350455,
          0.35039914803256644,
          0.3501377332326396,
          0.3495178114941332,
          0.34805448783080917,
          0.34805921107167953,
          0.3474927139349047,
          0.3473619970214304,
          0.3473035145590044,
          0.34727336718781415,
          0.3470541647636245,
          0.3472776553900314,
          0.3479090043770902,
          0.34717055632899924,
          0.34715474985713524,
          0.3472474085271238,
          0.347176217901579,
          0.3469553392267216,
          0.3473107103913682,
          0.34738094666049163,
          0.34716039436243146,
          0.346935809347146,
          0.34691692086677145,
          0.34732449921888814,
          0.3485397783022943,
          0.34952911035059664,
          0.3484508427763965,
          0.34928869472040364,
          0.34799107388006206,
          0.3484569478004146,
          0.34777323935586935,
          0.3476278318960283,
          0.34634635118702617,
          0.3465603467761283,
          0.3461310399549066,
          0.3463268921661518,
          0.34636611106627674,
          0.34665353433788765,
          0.3477724817170953,
          0.3516009371918467,
          0.34919169256327176,
          0.34889750870843045,
          0.347964217150969,
          0.3472833290917232,
          0.3525589622170686,
          0.3505239409431199,
          0.34974095084647944,
          0.3490380181677522,
          0.35263424333189586,
          0.35212170176640134,
          0.35043896500743815,
          0.3505778888961005,
          0.35028327049401525,
          0.34922887957824866,
          0.34828857942497493,
          0.3455152692583858,
          0.345351357987815,
          0.3452071739519488,
          0.3453274565440876,
          0.3470967258834874,
          0.3487442791230576,
          0.35142449272547316,
          0.3519281602822167,
          0.34786129052255726,
          0.3461211476968635,
          0.345626268162593,
          0.34531584045895297,
          0.3455581265606792,
          0.3466411043217345,
          0.3454467576775379,
          0.3464037343207198,
          0.344918039999562,
          0.34475998636368665,
          0.3468788688414273,
          0.3487533067357529,
          0.3464551750245441,
          0.3445346622030025,
          0.3450141282116773,
          0.34705756736394217,
          0.3448462209254128,
          0.34395022283698096,
          0.343986687658019,
          0.3442072593360807,
          0.345315237086234,
          0.3438799053187921,
          0.3446505525799267,
          0.34398922376105384,
          0.3441136745688349,
          0.34583175081780043,
          0.34737033937504225,
          0.35374404107618374,
          0.35590087793512865,
          0.35834738908979513,
          0.36061948054454124,
          0.36085313732553587,
          0.353765855953395,
          0.3526761558344938,
          0.35251871058791895,
          0.3490264647007065,
          0.35043209726163416,
          0.35121628767668517,
          0.3515823302861726,
          0.34901103835487823,
          0.35100302037072867,
          0.34632202934076656,
          0.3446417344842813,
          0.3425070455925459,
          0.34278816605090745,
          0.3423846752485672,
          0.34229784437989813,
          0.3430256220459967,
          0.34241541256210645,
          0.34261346117888136,
          0.3424129823359204,
          0.3425809851328121,
          0.3421903610440535,
          0.3431944287398194,
          0.34661721049427696,
          0.346151792672006,
          0.34386469917829027,
          0.34688491043915554,
          0.34819411530891936,
          0.3439075541313043,
          0.34518625276890313,
          0.34569286069395555,
          0.343757030543036,
          0.34505084010068365,
          0.3497047102758592,
          0.3458023143641807,
          0.3445846392782621,
          0.3435222486834359,
          0.3415458168703544,
          0.34149292924840163,
          0.3417615562014812,
          0.3419507814927601,
          0.34144212863590845,
          0.3415883656694881,
          0.34150058837857883,
          0.34174108718290236,
          0.34293520314316683,
          0.341831808883518,
          0.3422946856026922,
          0.343178444185775,
          0.3442979972835586,
          0.344033457852207,
          0.34837509418403434,
          0.34469061613698565,
          0.3438553609960969,
          0.3418491511529439,
          0.3437510668877027,
          0.3458618830671835,
          0.34920048305524676,
          0.350741603884588,
          0.3606347115414438,
          0.3544085828164809,
          0.35634247289760507,
          0.3571738893181881,
          0.3534858207050602,
          0.3533649265660758,
          0.3569116544032617,
          0.3530190088284307,
          0.35212270457530476,
          0.3443593413025453,
          0.3446734798841254,
          0.3483779973564103,
          0.34604640644012014,
          0.3439511629532134,
          0.3432287676513738,
          0.3463283679159896,
          0.3466782612525779,
          0.3510825389835671,
          0.35430885045995575,
          0.34987670371699914,
          0.34614855641289227,
          0.34368886882083255,
          0.34296803493677475,
          0.34797373461843645,
          0.3449557366772383,
          0.34058022062955234,
          0.3390003041350667,
          0.33900855512750006,
          0.33867256842525645,
          0.3388798886759087,
          0.3388823995448387,
          0.3400544698411352,
          0.34162622318318,
          0.3416473788671036,
          0.3392091229256448,
          0.3406747040979636,
          0.3421926445258573,
          0.3392574575757788,
          0.34074484097627517,
          0.3386110945724714,
          0.3388623303118093,
          0.3388671009047865,
          0.33855030236242156,
          0.3418309290110252,
          0.3422475384342344,
          0.3414895051743403,
          0.34508479265878556,
          0.3508736748336852,
          0.34549320606289324,
          0.3415749374951606,
          0.34316236928729554,
          0.35058447398266973,
          0.34870004287608825,
          0.34605556583025,
          0.34498246921062037,
          0.3437812888521099,
          0.34253814076639333,
          0.3404892994579505,
          0.34307421000159166,
          0.3500538989872141,
          0.34859570733162276,
          0.3478508513032094,
          0.3472822344768333,
          0.34233536990245744,
          0.3381350865608924,
          0.3390667372775868,
          0.3381371030006971,
          0.33810947910682626,
          0.33730386110724847,
          0.3369733254696601,
          0.33994324866011505,
          0.3449350069870776,
          0.3471689518413224,
          0.3464333722289142,
          0.34435873894545305,
          0.3450959456677942,
          0.33968592058522096,
          0.3436712528625134,
          0.3425291111607887,
          0.3476260970820632,
          0.3452099342060999,
          0.34629820346210405,
          0.34726809661207225,
          0.34340835505127404,
          0.3424989381183108,
          0.34716539682380015,
          0.35721063168673095,
          0.3557789882211993,
          0.35534701283172454,
          0.35175060718507467,
          0.35016765755041945,
          0.3468493866025224,
          0.34679408922518956,
          0.3480649699526921,
          0.3490985906507465,
          0.33966461401396164,
          0.342836226081184,
          0.3416437422095713,
          0.3461608582987797,
          0.3420720076937815,
          0.33911913591960785,
          0.3396839939850194,
          0.33947821799916716,
          0.33859751412650835,
          0.34094822824857224,
          0.3374200200989725,
          0.33662577684197464,
          0.33661295298262733,
          0.33566312772209267,
          0.33564786507689875,
          0.33677041008176023,
          0.33551892582621085,
          0.3359756752953498,
          0.33861547342280346,
          0.3384614138841431,
          0.33804469591079456,
          0.33593655281326135,
          0.33858688712390395,
          0.3389844346674097,
          0.3384010927019038,
          0.3394424467626061,
          0.336836487843232,
          0.3430373694984672,
          0.34617361154232323,
          0.3443710279789121,
          0.3431190628077801,
          0.3447018112621382,
          0.3416438670991204,
          0.33955530385275196,
          0.3376993366085251,
          0.3382766227140825,
          0.338022567847322,
          0.3376334705464781,
          0.3384906681255762,
          0.3401295894109569,
          0.33849098398121147,
          0.3381386542390243,
          0.3366420516466855,
          0.33790105802664977,
          0.336629594307912,
          0.3406432122748704,
          0.337709293654605,
          0.33762332821148366,
          0.336328007422313,
          0.3376407328603087,
          0.343780152589606,
          0.34241612815248623,
          0.3376735823624397,
          0.3415452189154566,
          0.3444231145832074,
          0.3398001710422495,
          0.3400887338703955,
          0.34113956686988806,
          0.3397493497920319,
          0.34511279909615705,
          0.3441684901686187,
          0.3491265422408395
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Objective Function Over Iterations"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Iteration"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Objective function"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "lamb = 0\n",
    "n_iter = 10000\n",
    "n_batch = 1\n",
    "gamma = 0.05\n",
    "# gamma = lambda t: 1 / np.sqrt(t)\n",
    "\n",
    "mlr = MySGDLogisticRegression(gamma, n_iter, lamb, n_batch=n_batch, random_state=None)\n",
    "mlr.fit(X_train, y_train)\n",
    "print(\"Test accuracy\", mlr.score(X_test, y_test))\n",
    "\n",
    "obj_list = mlr.obj_list_\n",
    "iter_list = np.arange(len(obj_list)) * mlr.freq_obj_eval\n",
    "\n",
    "fig = px.line(x=iter_list, y=obj_list, labels={'x': 'Iteration', 'y': 'Objective function'}, title='Objective Function Over Iterations')\n",
    "fig.update_layout(xaxis_title='Iteration', yaxis_title='Objective function')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2 (private SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now implement and experiment with DP-SGD:\n",
    "1. Given the normalization applied to the data, what is the sensitivity of an individual gradient?\n",
    "2. Following the model of the function `sgd`, implement a new function `private_sgd` which implements DP-SGD **with mini-batch size of 1 and no regularization**. It can take as input the desired value of $\\epsilon$ and $\\delta$ for the $(\\epsilon,\\delta)$-DP, or alternatively the standard deviation of the Gaussian noise to add at each iteration. Note: you do not need to make the objective plotting part private (this is only for monitoring).\n",
    "3. Following the model of the class `MySGDLogisticRegression`, implement a new class `MyPrivateSGDLogisticRegression` which implements differentially private logistic regression trained using your DP-SGD implementation above.\n",
    "4. Experiment with different values of $\\epsilon$ and $\\delta$, number of iterations and step size, and study the effect on the convergence of SGD as well as the test accuracy of the resulting model. Describe your observations. How does the level of privacy affect the choice of the number of iterations? How can we choose the number of iterations and step size in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sensitivity of an individual gradient is the maximum difference between two gradients of the loss function. That is to say: $\\max_{x,y,x',y'}\\| \\nabla L(\\theta;x,y) - \\nabla L(\\theta;x',y')\\|_2$, where $L(\\theta;x,y)$ is the loss function of the model with respect to the $\\theta$ and $(x,y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def private_sgd(X, y, gamma, n_iter, obj_and_grad, theta_init, eps, data, n_batch=1, freq_obj_eval=10,\n",
    "        n_obj_eval=1000, random_state=None):\n",
    "    \"\"\"Stochastic Gradient Descent (SGD) algorithm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape (n, d)\n",
    "        The data\n",
    "    y : array, shape (n,)\n",
    "        Binary labels (-1, 1).\n",
    "    gamma : float | callable\n",
    "        The step size. Can be a constant float or a function\n",
    "        that allows to have a variable step size\n",
    "    n_iter : int\n",
    "        The number of iterations\n",
    "    obj_and_grad : callable\n",
    "        A function which takes as a vector of shape (p,), a dataset of shape (n_batch, d)\n",
    "        and a label vector of shape (n_batch,), and returns the objective value and gradient.\n",
    "    theta_init : array, shape (p,)\n",
    "        The initial value for the model parameters\n",
    "    n_batch : int\n",
    "        Size of the mini-batch to use at each iteration of SGD.\n",
    "    freq_obj_eval : int\n",
    "        Specifies the frequency (in number of iterations) at which we compute the objective\n",
    "    n_obj_eval : int\n",
    "        The number of points on which we evaluate the objective\n",
    "    eps : float\n",
    "        Parameter epsilon of differential privacy\n",
    "    delta : float\n",
    "        Parameter delta of differential privacy\n",
    "    random_state : int\n",
    "        Random seed to make the algorithm deterministic\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    theta : array, shape=(p,)\n",
    "        The final value of the model parameters\n",
    "    obj_list : list of length (n_iter / freq_obj_eval)\n",
    "        A list containing the value of the objective function computed every freq_obj_eval iterations\n",
    "    \"\"\"\n",
    "    \n",
    "    rng = np.random.RandomState(random_state)\n",
    "    n, d = X.shape\n",
    "    p = theta_init.shape[0]\n",
    "    \n",
    "    theta = theta_init.copy()\n",
    "\n",
    "    # if a constant step size was provided, we turn it into a constant function\n",
    "    if not callable(gamma):\n",
    "        def gamma_func(t):\n",
    "            return gamma\n",
    "    else:\n",
    "        gamma_func = gamma\n",
    "    \n",
    "    # list to record the evolution of the objective (for plotting)\n",
    "    obj_list = []\n",
    "    # we draw a fixed subset of points to monitor the objective\n",
    "    idx_eval = rng.randint(0, n, n_obj_eval)\n",
    "\n",
    "    for t in range(n_iter):\n",
    "        if t % freq_obj_eval == 0:\n",
    "            # evaluate objective\n",
    "            obj, _ = obj_and_grad(theta, X[idx_eval, :], y[idx_eval])\n",
    "            obj_list.append(obj)\n",
    "    \n",
    "        idx_batch = rng.randint(0, n, n_batch)\n",
    "        X_batch = X[idx_batch, :]\n",
    "        y_batch = y[idx_batch]\n",
    "        sigma = 16 * np.sqrt(n_iter * np.log(2 / delta) * np.log(2.5 * n_iter / (delta * n))) / (n * eps)\n",
    "        eta = np.random.normal(0, sigma, p)\n",
    "        \n",
    "        _, grad = obj_and_grad(theta, X_batch, y_batch)\n",
    "        \n",
    "        theta -= (gamma_func(t) + eta) * grad\n",
    "        \n",
    "    return theta, obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPrivateSGDLogisticRegression(BaseEstimator, LinearClassifierMixin, SparseCoefMixin):\n",
    "    \"\"\"Our own sklearn estimator for logistic regression defined as:\n",
    "    min (1/n) \\sum_i log_loss(theta;X[i,:],y[i]) + (lamb / 2) \\|w\\|^2,\n",
    "    where theta = [w b]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gamma : float | callable\n",
    "        The step size. Can be a constant float or a function\n",
    "        that allows to have a variable step size\n",
    "    n_iter : int\n",
    "        The number of iterations\n",
    "    lamb : float\n",
    "        The L2 regularization parameter\n",
    "    n_batch : int\n",
    "        Size of the mini-batch to use at each iteration of SGD.\n",
    "    freq_obj_eval : int\n",
    "        Specifies the frequency (in number of iterations) at which we compute the objective\n",
    "    n_obj_eval : int\n",
    "        The number of points on which we evaluate the objectuve\n",
    "    random_state : int\n",
    "        Random seed to make the algorithm deterministic\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    coef_ : (p,)\n",
    "        The weights of the logistic regression model.\n",
    "    intercept_ : (1,)\n",
    "        The intercept term of the logistic regression model.\n",
    "    obj_list_: list of length (n_iter / freq_obj_eval)\n",
    "        A list containing the value of the objective function computed every freq_loss_eval iterations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gamma, n_iter, eps, delta, lamb=0, n_batch=1, freq_obj_eval=10, n_obj_eval=1000, random_state=None):\n",
    "        self.gamma = gamma\n",
    "        self.n_iter = n_iter\n",
    "        self.lamb = lamb\n",
    "        self.n_batch = n_batch\n",
    "        self.freq_obj_eval = freq_obj_eval\n",
    "        self.n_obj_eval = n_obj_eval\n",
    "        self.random_state = random_state\n",
    "        self.eps = eps\n",
    "        self.delta = delta\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # WARNING: assumes labels are -1, 1\n",
    "        X, y = check_X_y(X, y, accept_sparse='csr', dtype=[np.float64, np.float32], order=\"C\")\n",
    "        self.classes_ = np.unique(y)    \n",
    "        \n",
    "        p = X.shape[1]\n",
    "        theta_init = np.zeros(p+1) # initialize parameters to zero\n",
    "        # define the function for value and gradient needed by SGD\n",
    "        obj_grad = lambda theta, X, y: my_logistic_obj_and_grad(theta, X, y, lamb=self.lamb)\n",
    "        theta, obj_list = private_sgd(X, y, self.gamma, self.n_iter, obj_grad, theta_init, self.eps, self.delta, self.n_batch,\n",
    "                              self.freq_obj_eval, self.n_obj_eval, self.random_state)\n",
    "        \n",
    "        # save the learned model into the appropriate quantities used by sklearn\n",
    "        self.intercept_ = np.expand_dims(theta[-1], axis=0)\n",
    "        self.coef_ = np.expand_dims(theta[:-1], axis=0)\n",
    "        \n",
    "        # also save list of objective values during optimization for plotting\n",
    "        self.obj_list_ = obj_list\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lamb = 0\n",
    "n_iter = 500\n",
    "n_batch = 1\n",
    "gamma = 0.2\n",
    "# gamma = lambda t: 1 / np.sqrt(t)\n",
    "\n",
    "eps_list = np.linspace(0.1, 5.0, num=5)\n",
    "delta_list = [1. / n_train**2, 1. / n_train**4]\n",
    "n_runs = 10\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "accuracy = np.zeros((len(eps_list), len(delta_list), n_runs))\n",
    "for j, delta in enumerate(delta_list):\n",
    "    for i, eps in enumerate(eps_list):\n",
    "        for r in range(n_runs):\n",
    "            mlr = MyPrivateSGDLogisticRegression(gamma, n_iter, eps, delta, lamb, n_batch=n_batch, random_state=r)\n",
    "            mlr.fit(X_train, y_train)\n",
    "            accuracy[i, j, r] = mlr.score(X_test, y_test)\n",
    "\n",
    "                    \n",
    "    \n",
    "    ax.errorbar(eps_list, accuracy[:, j, :].mean(axis=1), accuracy[:, j, :].std(axis=1),\n",
    "                    label='DP-SGD ($\\delta$=' + \"{:.2e}\".format(delta) + ')')\n",
    "\n",
    "plt.xlabel(\"$\\epsilon$\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Bonus Question</font> (extending the scope of private SGD)\n",
    "*(You won't be penalized if you don't answer this question; but can get bonus points if you do)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the following extensions, which were briefly discussed in the lecture:\n",
    "1. *$\\ell_2$-regularization*: What is the sensitivity of the stochastic gradient when adding $\\ell_2$-regularization to the objective (parameter `lamb` in the code above)? Adapt your code if needed.\n",
    "2. *Mini-batch*: What is the sensitivity of a stochastic gradient when it is evaluated on a mini-batch of $b$ data points (parameter `n_batch` in the code above)? Adapt your code if needed.\n",
    "3. *Gradient clipping*: If the loss function $L$ is not Lipschitz, or when the Lipschitz constant is difficult to bound, the idea of gradient clipping consists in rescaling each individual gradient that have a norm larger than some constant $C$ to have norm equal to $C$:\n",
    "$$\\text{clip}(\\nabla L(\\theta;x,y), C) = \\min\\Big(1,\\frac{C}{\\|\\nabla L(\\theta;x,y)\\|_2}\\Big)\\nabla L(\\theta;x,y)$$\n",
    "\n",
    "Explain how this allows to bound the gradient sensitivity without any assumption on the Lipschitzness of the loss. Implement this variant in a function `private_sgd_with_clipping` and explore how to choose the value of $C$ for logistic regression on the *unnormalized* version of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> These extensions to the basic setup of differentially private stochastic gradient descent (SGD) are crucial for enhancing privacy while maintaining the utility of the model. Let's delve into each of them: \n",
    "> - **ℓ2-Regularization :** \n",
    ">> ℓ2-regularization adds a penalty to the loss function proportional to the square of the magnitude of the coefficients. \n",
    ">> The sensitivity of the stochastic gradient with ℓ2-regularization does not change the fundamental sensitivity of the SGD step because the regularization term depends on the parameters $\\theta$ rather than the data. However, it indirectly influences sensitivity by potentially keeping the weights smaller, which can affect the gradients' magnitude through the loss function.\n",
    "\n",
    "> - **Mini-batch :**\n",
    ">> When evaluating the stochastic gradient on a mini-batch of b data points, the sensitivity of the stochastic gradient increases linearly with the batch size b. This is because the gradient is now the sum of the gradients over b points, making the maximum change (sensitivity) b times larger if each point could change the gradient by a maximum amount. \n",
    ">>\n",
    ">> The sensitivity of a stochastic gradient evaluated on a mini-batch of size b is b times the sensitivity of the gradient evaluated on a single data point, assuming the worst-case scenario where each data point in the batch could contribute to the maximum possible change in the gradient.\n",
    "\n",
    "> - **Gradient Clipping**\n",
    ">> Gradient clipping bounds the sensitivity of the gradient without any assumption on the Lipschitzness of the loss by ensuring that no individual gradient exceeds a norm of C. This is crucial in differentially private SGD, where controlling the gradient's sensitivity is necessary to apply noise for privacy.\n",
    ">>\n",
    ">> By clipping each gradient to have a maximum norm of C, we ensure that the maximum contribution of any single data point to the gradient is bounded. This allows us to add noise scaled to C (plus any additional sensitivity from batching or other sources) to achieve differential privacy. The choice of C is critical: too small, and we might lose important signal in the gradients; too large, and we don't sufficiently bound sensitivity to add effective noise for privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Choosing C for logistic regression on an unnormalized dataset involves experimentation and domain knowledge. Too small a C may lead to underfitting by clipping too much useful signal, while too large a C might not sufficiently protect privacy. A practical approach is to start with a C based on observed gradients' norms during initial non-private training runs and adjust based on privacy-utility trade-offs observed in validation performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
